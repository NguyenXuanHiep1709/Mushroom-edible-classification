{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/mushroom_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>season</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.807467</td>\n",
       "      <td>1545</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1461</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.807467</td>\n",
       "      <td>1557</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1371</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.612496</td>\n",
       "      <td>1566</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1261</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.787572</td>\n",
       "      <td>1566</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1305</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.711971</td>\n",
       "      <td>1464</td>\n",
       "      <td>11</td>\n",
       "      <td>0.943195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-diameter  cap-shape  gill-attachment  gill-color  stem-height  \\\n",
       "0          1372          2                2          10     3.807467   \n",
       "1          1461          2                2          10     3.807467   \n",
       "2          1371          2                2          10     3.612496   \n",
       "3          1261          6                2          10     3.787572   \n",
       "4          1305          6                2          10     3.711971   \n",
       "\n",
       "   stem-width  stem-color    season  class  \n",
       "0        1545          11  1.804273      1  \n",
       "1        1557          11  1.804273      1  \n",
       "2        1566          11  1.804273      1  \n",
       "3        1566          11  1.804273      1  \n",
       "4        1464          11  0.943195      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54035, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6347019443873237"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0, stratify = y)\n",
    "X_val, X_train, y_val, y_train = train_test_split(X_train, y_train, test_size=0.1, random_state=0, stratify=y_train)\n",
    "LR.fit(X_train, y_train).score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46211, 9)\n"
     ]
    }
   ],
   "source": [
    "# Xử lý outlier\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Hàm để loại bỏ outlier bằng Z-score\n",
    "def remove_outliers_zscore(df, column, threshold=2):\n",
    "    z_scores = np.abs(stats.zscore(df[column]))\n",
    "    return df[(z_scores < threshold)]\n",
    "\n",
    "# Loại bỏ outlier trong các cột 'stem-width', 'stem-height'\n",
    "df = remove_outliers_zscore(df, 'cap-diameter')\n",
    "df = remove_outliers_zscore(df, 'stem-width')\n",
    "df = remove_outliers_zscore(df, 'stem-height')\n",
    "\n",
    "print(df.shape)  # Kiểm tra kích thước dữ liệu sau khi loại bỏ outlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6350520972481967"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0, stratify = y)\n",
    "X_val, X_train, y_val, y_train = train_test_split(X_train, y_train, test_size=0.1, random_state=0, stratify=y_train)\n",
    "LR.fit(X_train, y_train).score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuẩn hóa\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaler = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.647929468340903"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaler, y, test_size=0.1, random_state=0, stratify = y)\n",
    "X_val, X_train, y_val, y_train = train_test_split(X_train, y_train, test_size=0.1, random_state=0, stratify=y_train)\n",
    "LR.fit(X_train, y_train).score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "25 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [0.63740975 0.63139811        nan 0.64534099 0.64678446 0.64678446\n",
      " 0.64510032 0.64582292        nan 0.64461984 0.64461955 0.64485993\n",
      " 0.64654321 0.64630282        nan 0.64702426 0.64702426 0.64702426\n",
      " 0.64678359 0.64678359        nan 0.64678388 0.64678388 0.64678388\n",
      " 0.64678388 0.64678388        nan 0.64678388 0.64678388 0.64678388]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.647929468340903"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dùng Regularization và cross validation\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga', 'sag']\n",
    "}\n",
    "LR_regu = GridSearchCV(LR, param_grid, cv=5, scoring='accuracy')\n",
    "LR_regu.fit(X_train, y_train).score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_regu.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "25 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [0.63212215 0.63212331        nan 0.64101841 0.63909475 0.63909475\n",
      " 0.64053735 0.64029639        nan 0.64414254 0.64486427 0.64486427\n",
      " 0.64534562 0.64534533        nan 0.6455863  0.6455863  0.6455863\n",
      " 0.64534591 0.6455863         nan 0.64534591 0.64534591 0.64534591\n",
      " 0.64534591 0.64534591        nan 0.64534591 0.64534591 0.64534591]\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "25 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [0.63645486 0.63405073        nan 0.63934092 0.63910054 0.63910054\n",
      " 0.64463025 0.64390939        nan 0.64438958 0.64463025 0.64463025\n",
      " 0.64775641 0.64703526        nan 0.6477567  0.6477567  0.6477567\n",
      " 0.64703526 0.64679487        nan 0.64703526 0.64703526 0.64703526\n",
      " 0.64703526 0.64703526        nan 0.64703526 0.64703526 0.64703526]\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "25 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [0.64029436 0.6400534         nan 0.65183572 0.65087389 0.65087389\n",
      " 0.65375879 0.65039283        nan 0.65472178 0.65544322 0.65544322\n",
      " 0.65303851 0.65231735        nan 0.65351928 0.65351928 0.65351928\n",
      " 0.65351928 0.65327889        nan 0.65351928 0.65351928 0.65351928\n",
      " 0.65351928 0.65351928        nan 0.65351928 0.65351928 0.65351928]\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "25 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [0.64366495 0.63981822        nan 0.65616611 0.65472236 0.65472236\n",
      " 0.65328034 0.65424246        nan 0.65448458 0.65376255 0.65376255\n",
      " 0.65304169 0.65232054        nan 0.65256034 0.65256034 0.65256034\n",
      " 0.65256034 0.65256034        nan 0.65256034 0.65256034 0.65256034\n",
      " 0.65256034 0.65256034        nan 0.65256034 0.65256034 0.65256034]\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "25 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [0.61769358 0.61504964        nan 0.63524455 0.63596628 0.63596628\n",
      " 0.63115714 0.62971484        nan 0.63163733 0.63211753 0.63211753\n",
      " 0.63187801 0.63187801        nan 0.63163762 0.63139724 0.63139724\n",
      " 0.63139724 0.63139724        nan 0.63139724 0.63139724 0.63139724\n",
      " 0.63139724 0.63139724        nan 0.63139724 0.63139724 0.63139724]\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "25 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [0.64029754 0.63380687        nan 0.64919583 0.65015852 0.65015852\n",
      " 0.65087881 0.64991727        nan 0.6540041  0.65280159 0.65280159\n",
      " 0.65256092 0.65280131        nan 0.65183948 0.65183948 0.65183948\n",
      " 0.65208015 0.65183948        nan 0.65208015 0.65208015 0.65208015\n",
      " 0.65208015 0.65208015        nan 0.65208015 0.65208015 0.65208015]\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "25 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [0.63067869 0.63164514        nan 0.64293975 0.63861138 0.63861138\n",
      " 0.64510263 0.64510321        nan 0.64486196 0.64510234 0.64510234\n",
      " 0.64606388 0.64606388        nan 0.64510205 0.64510205 0.64510205\n",
      " 0.64558282 0.64534244        nan 0.64558282 0.64558282 0.64534244\n",
      " 0.64558282 0.64558282        nan 0.64558282 0.64558282 0.64558282]\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "25 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [0.64582957 0.64029957        nan 0.65737266 0.65809295 0.65809295\n",
      " 0.6549665  0.65520804        nan 0.6597768  0.65905507 0.65905507\n",
      " 0.6588141  0.65737179        nan 0.65953526 0.65953526 0.65929487\n",
      " 0.65929487 0.65929487        nan 0.65929487 0.65929487 0.65929487\n",
      " 0.65929487 0.65929487        nan 0.65929487 0.65929487 0.65929487]\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "25 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [0.62057877 0.6222632         nan 0.63356273 0.63428272 0.63428272\n",
      " 0.6316382  0.63380224        nan 0.63332061 0.63356099 0.63356099\n",
      " 0.63380195 0.63380166        nan 0.63380109 0.63380109 0.63380109\n",
      " 0.63380109 0.63380109        nan 0.63380109 0.63380109 0.63380109\n",
      " 0.63380109 0.63380109        nan 0.63380109 0.63380109 0.63380109]\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "25 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [0.61890447 0.61722004        nan 0.63357025 0.63429082 0.63429082\n",
      " 0.63164804 0.63260842        nan 0.63621477 0.63597438 0.63597438\n",
      " 0.63717717 0.63741727        nan 0.6369365  0.6369365  0.6369365\n",
      " 0.63765794 0.63765794        nan 0.63765794 0.63765794 0.63765794\n",
      " 0.63765794 0.63741727        nan 0.63741727 0.63741727 0.63741727]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6464600587763826"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dùng Bagging\n",
    "LR_bag = BaggingClassifier(LR_regu, n_estimators=10, random_state=0)\n",
    "LR_bag.fit(X_train, y_train).score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán\n",
    "y_pre = LR_bag.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.633703</td>\n",
       "      <td>0.583372</td>\n",
       "      <td>0.607497</td>\n",
       "      <td>2153.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.660227</td>\n",
       "      <td>0.705954</td>\n",
       "      <td>0.682325</td>\n",
       "      <td>2469.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.648853</td>\n",
       "      <td>0.648853</td>\n",
       "      <td>0.648853</td>\n",
       "      <td>0.648853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.646965</td>\n",
       "      <td>0.644663</td>\n",
       "      <td>0.644911</td>\n",
       "      <td>4622.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.647872</td>\n",
       "      <td>0.648853</td>\n",
       "      <td>0.647469</td>\n",
       "      <td>4622.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.633703  0.583372  0.607497  2153.000000\n",
       "1              0.660227  0.705954  0.682325  2469.000000\n",
       "accuracy       0.648853  0.648853  0.648853     0.648853\n",
       "macro avg      0.646965  0.644663  0.644911  4622.000000\n",
       "weighted avg   0.647872  0.648853  0.647469  4622.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate = classification_report(y_test, y_pre, output_dict=True)\n",
    "evaluate_df = pd.DataFrame(evaluate).transpose()\n",
    "evaluate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x24547b93860>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf = confusion_matrix(y_test, y_pre, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cf)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9486775313919316"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdaBoost cho mô hình Decision Tree\n",
    "DT_param_grid = {\n",
    "    'n_estimators': [50, 100, 200], # Số lượng mô hình con\n",
    "    'learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "DT = DecisionTreeClassifier(max_depth=3)\n",
    "DT_AdaBoost = GridSearchCV(AdaBoostClassifier(DT, random_state=0), param_grid=DT_param_grid)\n",
    "DT_AdaBoost.fit(X_train, y_train).score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9760886989046219"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "GB_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'max_depth': [1, 3, 5, 7]\n",
    "}\n",
    "\n",
    "GB = GradientBoostingClassifier(max_depth=1,random_state=0)\n",
    "# n_jobs=-1: Sử dụng tất cả các lõi CPU sẵn có để thực hiện việc tìm kiếm siêu tham số 1 cách song song\n",
    "GB_grid_search = GridSearchCV(GB, param_grid=GB_param_grid, n_jobs=-1)\n",
    "GB_grid_search.fit(X_train, y_train).score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.969124</td>\n",
       "      <td>0.976777</td>\n",
       "      <td>0.972935</td>\n",
       "      <td>2153.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.979608</td>\n",
       "      <td>0.972864</td>\n",
       "      <td>0.976224</td>\n",
       "      <td>2469.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.974686</td>\n",
       "      <td>0.974686</td>\n",
       "      <td>0.974686</td>\n",
       "      <td>0.974686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.974366</td>\n",
       "      <td>0.974820</td>\n",
       "      <td>0.974580</td>\n",
       "      <td>4622.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.974725</td>\n",
       "      <td>0.974686</td>\n",
       "      <td>0.974692</td>\n",
       "      <td>4622.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.969124  0.976777  0.972935  2153.000000\n",
       "1              0.979608  0.972864  0.976224  2469.000000\n",
       "accuracy       0.974686  0.974686  0.974686     0.974686\n",
       "macro avg      0.974366  0.974820  0.974580  4622.000000\n",
       "weighted avg   0.974725  0.974686  0.974692  4622.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre = GB_grid_search.predict(X_test)\n",
    "evaluate = classification_report(y_test, y_pre, output_dict=True)\n",
    "evaluate_df = pd.DataFrame(evaluate).transpose()\n",
    "evaluate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py:160: UserWarning: [16:52:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.64376\n",
      "[1]\tvalidation_0-logloss:0.60526\n",
      "[2]\tvalidation_0-logloss:0.57259\n",
      "[3]\tvalidation_0-logloss:0.54233\n",
      "[4]\tvalidation_0-logloss:0.51535\n",
      "[5]\tvalidation_0-logloss:0.49549\n",
      "[6]\tvalidation_0-logloss:0.47571\n",
      "[7]\tvalidation_0-logloss:0.46070\n",
      "[8]\tvalidation_0-logloss:0.44391\n",
      "[9]\tvalidation_0-logloss:0.43094\n",
      "[10]\tvalidation_0-logloss:0.42015\n",
      "[11]\tvalidation_0-logloss:0.40460\n",
      "[12]\tvalidation_0-logloss:0.39104\n",
      "[13]\tvalidation_0-logloss:0.38219\n",
      "[14]\tvalidation_0-logloss:0.37252\n",
      "[15]\tvalidation_0-logloss:0.36248\n",
      "[16]\tvalidation_0-logloss:0.35345\n",
      "[17]\tvalidation_0-logloss:0.34527\n",
      "[18]\tvalidation_0-logloss:0.33622\n",
      "[19]\tvalidation_0-logloss:0.32659\n",
      "[20]\tvalidation_0-logloss:0.31710\n",
      "[21]\tvalidation_0-logloss:0.31212\n",
      "[22]\tvalidation_0-logloss:0.29934\n",
      "[23]\tvalidation_0-logloss:0.29032\n",
      "[24]\tvalidation_0-logloss:0.28369\n",
      "[25]\tvalidation_0-logloss:0.27350\n",
      "[26]\tvalidation_0-logloss:0.26798\n",
      "[27]\tvalidation_0-logloss:0.26358\n",
      "[28]\tvalidation_0-logloss:0.25725\n",
      "[29]\tvalidation_0-logloss:0.25497\n",
      "[30]\tvalidation_0-logloss:0.25142\n",
      "[31]\tvalidation_0-logloss:0.24717\n",
      "[32]\tvalidation_0-logloss:0.24525\n",
      "[33]\tvalidation_0-logloss:0.24192\n",
      "[34]\tvalidation_0-logloss:0.23872\n",
      "[35]\tvalidation_0-logloss:0.23682\n",
      "[36]\tvalidation_0-logloss:0.22928\n",
      "[37]\tvalidation_0-logloss:0.22731\n",
      "[38]\tvalidation_0-logloss:0.22578\n",
      "[39]\tvalidation_0-logloss:0.21931\n",
      "[40]\tvalidation_0-logloss:0.21769\n",
      "[41]\tvalidation_0-logloss:0.21357\n",
      "[42]\tvalidation_0-logloss:0.21167\n",
      "[43]\tvalidation_0-logloss:0.20812\n",
      "[44]\tvalidation_0-logloss:0.20193\n",
      "[45]\tvalidation_0-logloss:0.20055\n",
      "[46]\tvalidation_0-logloss:0.19548\n",
      "[47]\tvalidation_0-logloss:0.19315\n",
      "[48]\tvalidation_0-logloss:0.19169\n",
      "[49]\tvalidation_0-logloss:0.19090\n",
      "[50]\tvalidation_0-logloss:0.19018\n",
      "[51]\tvalidation_0-logloss:0.18561\n",
      "[52]\tvalidation_0-logloss:0.18163\n",
      "[53]\tvalidation_0-logloss:0.18119\n",
      "[54]\tvalidation_0-logloss:0.17936\n",
      "[55]\tvalidation_0-logloss:0.17885\n",
      "[56]\tvalidation_0-logloss:0.17794\n",
      "[57]\tvalidation_0-logloss:0.17364\n",
      "[58]\tvalidation_0-logloss:0.17130\n",
      "[59]\tvalidation_0-logloss:0.17065\n",
      "[60]\tvalidation_0-logloss:0.16780\n",
      "[61]\tvalidation_0-logloss:0.16595\n",
      "[62]\tvalidation_0-logloss:0.16525\n",
      "[63]\tvalidation_0-logloss:0.16458\n",
      "[64]\tvalidation_0-logloss:0.16198\n",
      "[65]\tvalidation_0-logloss:0.15837\n",
      "[66]\tvalidation_0-logloss:0.15480\n",
      "[67]\tvalidation_0-logloss:0.15458\n",
      "[68]\tvalidation_0-logloss:0.15100\n",
      "[69]\tvalidation_0-logloss:0.14943\n",
      "[70]\tvalidation_0-logloss:0.14782\n",
      "[71]\tvalidation_0-logloss:0.14693\n",
      "[72]\tvalidation_0-logloss:0.14669\n",
      "[73]\tvalidation_0-logloss:0.14610\n",
      "[74]\tvalidation_0-logloss:0.14588\n",
      "[75]\tvalidation_0-logloss:0.14569\n",
      "[76]\tvalidation_0-logloss:0.14449\n",
      "[77]\tvalidation_0-logloss:0.14430\n",
      "[78]\tvalidation_0-logloss:0.14263\n",
      "[79]\tvalidation_0-logloss:0.14178\n",
      "[80]\tvalidation_0-logloss:0.14153\n",
      "[81]\tvalidation_0-logloss:0.14010\n",
      "[82]\tvalidation_0-logloss:0.13961\n",
      "[83]\tvalidation_0-logloss:0.13939\n",
      "[84]\tvalidation_0-logloss:0.13887\n",
      "[85]\tvalidation_0-logloss:0.13774\n",
      "[86]\tvalidation_0-logloss:0.13609\n",
      "[87]\tvalidation_0-logloss:0.13513\n",
      "[88]\tvalidation_0-logloss:0.13474\n",
      "[89]\tvalidation_0-logloss:0.13457\n",
      "[90]\tvalidation_0-logloss:0.13434\n",
      "[91]\tvalidation_0-logloss:0.13426\n",
      "[92]\tvalidation_0-logloss:0.13341\n",
      "[93]\tvalidation_0-logloss:0.13330\n",
      "[94]\tvalidation_0-logloss:0.13227\n",
      "[95]\tvalidation_0-logloss:0.13140\n",
      "[96]\tvalidation_0-logloss:0.13114\n",
      "[97]\tvalidation_0-logloss:0.13091\n",
      "[98]\tvalidation_0-logloss:0.13013\n",
      "[99]\tvalidation_0-logloss:0.12987\n",
      "[100]\tvalidation_0-logloss:0.12952\n",
      "[101]\tvalidation_0-logloss:0.12905\n",
      "[102]\tvalidation_0-logloss:0.12591\n",
      "[103]\tvalidation_0-logloss:0.12567\n",
      "[104]\tvalidation_0-logloss:0.12523\n",
      "[105]\tvalidation_0-logloss:0.12264\n",
      "[106]\tvalidation_0-logloss:0.12246\n",
      "[107]\tvalidation_0-logloss:0.11891\n",
      "[108]\tvalidation_0-logloss:0.11785\n",
      "[109]\tvalidation_0-logloss:0.11691\n",
      "[110]\tvalidation_0-logloss:0.11466\n",
      "[111]\tvalidation_0-logloss:0.11387\n",
      "[112]\tvalidation_0-logloss:0.11197\n",
      "[113]\tvalidation_0-logloss:0.11135\n",
      "[114]\tvalidation_0-logloss:0.11024\n",
      "[115]\tvalidation_0-logloss:0.10981\n",
      "[116]\tvalidation_0-logloss:0.10943\n",
      "[117]\tvalidation_0-logloss:0.10885\n",
      "[118]\tvalidation_0-logloss:0.10740\n",
      "[119]\tvalidation_0-logloss:0.10705\n",
      "[120]\tvalidation_0-logloss:0.10671\n",
      "[121]\tvalidation_0-logloss:0.10675\n",
      "[122]\tvalidation_0-logloss:0.10669\n",
      "[123]\tvalidation_0-logloss:0.10660\n",
      "[124]\tvalidation_0-logloss:0.10606\n",
      "[125]\tvalidation_0-logloss:0.10585\n",
      "[126]\tvalidation_0-logloss:0.10582\n",
      "[127]\tvalidation_0-logloss:0.10564\n",
      "[128]\tvalidation_0-logloss:0.10403\n",
      "[129]\tvalidation_0-logloss:0.10398\n",
      "[130]\tvalidation_0-logloss:0.10318\n",
      "[131]\tvalidation_0-logloss:0.10294\n",
      "[132]\tvalidation_0-logloss:0.10291\n",
      "[133]\tvalidation_0-logloss:0.10217\n",
      "[134]\tvalidation_0-logloss:0.10128\n",
      "[135]\tvalidation_0-logloss:0.10076\n",
      "[136]\tvalidation_0-logloss:0.10060\n",
      "[137]\tvalidation_0-logloss:0.09984\n",
      "[138]\tvalidation_0-logloss:0.09958\n",
      "[139]\tvalidation_0-logloss:0.09920\n",
      "[140]\tvalidation_0-logloss:0.09786\n",
      "[141]\tvalidation_0-logloss:0.09721\n",
      "[142]\tvalidation_0-logloss:0.09632\n",
      "[143]\tvalidation_0-logloss:0.09560\n",
      "[144]\tvalidation_0-logloss:0.09527\n",
      "[145]\tvalidation_0-logloss:0.09512\n",
      "[146]\tvalidation_0-logloss:0.09416\n",
      "[147]\tvalidation_0-logloss:0.09369\n",
      "[148]\tvalidation_0-logloss:0.09356\n",
      "[149]\tvalidation_0-logloss:0.09352\n",
      "[150]\tvalidation_0-logloss:0.09340\n",
      "[151]\tvalidation_0-logloss:0.09337\n",
      "[152]\tvalidation_0-logloss:0.09339\n",
      "[153]\tvalidation_0-logloss:0.09346\n",
      "[154]\tvalidation_0-logloss:0.09270\n",
      "[155]\tvalidation_0-logloss:0.09216\n",
      "[156]\tvalidation_0-logloss:0.09195\n",
      "[157]\tvalidation_0-logloss:0.09167\n",
      "[158]\tvalidation_0-logloss:0.09122\n",
      "[159]\tvalidation_0-logloss:0.09051\n",
      "[160]\tvalidation_0-logloss:0.09053\n",
      "[161]\tvalidation_0-logloss:0.08992\n",
      "[162]\tvalidation_0-logloss:0.08984\n",
      "[163]\tvalidation_0-logloss:0.08976\n",
      "[164]\tvalidation_0-logloss:0.08953\n",
      "[165]\tvalidation_0-logloss:0.08959\n",
      "[166]\tvalidation_0-logloss:0.08958\n",
      "[167]\tvalidation_0-logloss:0.08901\n",
      "[168]\tvalidation_0-logloss:0.08861\n",
      "[169]\tvalidation_0-logloss:0.08851\n",
      "[170]\tvalidation_0-logloss:0.08850\n",
      "[171]\tvalidation_0-logloss:0.08846\n",
      "[172]\tvalidation_0-logloss:0.08846\n",
      "[173]\tvalidation_0-logloss:0.08852\n",
      "[174]\tvalidation_0-logloss:0.08837\n",
      "[175]\tvalidation_0-logloss:0.08774\n",
      "[176]\tvalidation_0-logloss:0.08736\n",
      "[177]\tvalidation_0-logloss:0.08739\n",
      "[178]\tvalidation_0-logloss:0.08734\n",
      "[179]\tvalidation_0-logloss:0.08706\n",
      "[180]\tvalidation_0-logloss:0.08671\n",
      "[181]\tvalidation_0-logloss:0.08601\n",
      "[182]\tvalidation_0-logloss:0.08598\n",
      "[183]\tvalidation_0-logloss:0.08540\n",
      "[184]\tvalidation_0-logloss:0.08496\n",
      "[185]\tvalidation_0-logloss:0.08460\n",
      "[186]\tvalidation_0-logloss:0.08412\n",
      "[187]\tvalidation_0-logloss:0.08405\n",
      "[188]\tvalidation_0-logloss:0.08399\n",
      "[189]\tvalidation_0-logloss:0.08386\n",
      "[190]\tvalidation_0-logloss:0.08378\n",
      "[191]\tvalidation_0-logloss:0.08365\n",
      "[192]\tvalidation_0-logloss:0.08300\n",
      "[193]\tvalidation_0-logloss:0.08292\n",
      "[194]\tvalidation_0-logloss:0.08243\n",
      "[195]\tvalidation_0-logloss:0.08224\n",
      "[196]\tvalidation_0-logloss:0.08186\n",
      "[197]\tvalidation_0-logloss:0.08154\n",
      "[198]\tvalidation_0-logloss:0.08150\n",
      "[199]\tvalidation_0-logloss:0.08137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py:160: UserWarning: [16:52:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\core.py:160: UserWarning: [16:52:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9725353994122362"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. XGBoost \n",
    "import xgboost as xgb\n",
    "\n",
    "# Sử dụng GPU để huấn luyện mô hình\n",
    "# use_label_encoder=False: sử dụng mã hóa nhãn -> số\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, tree_method='gpu_hist', eval_metric='logloss', random_state=0)\n",
    "xgb_grid_search = GridSearchCV(xgb_model, param_grid=GB_param_grid, n_jobs=-1)\n",
    "xgb_grid_search.fit(\n",
    "    X_train, y_train,\n",
    "    early_stopping_rounds=10, # Nếu không cải thiện sau 10 vòng lặp thì dừng\n",
    "    eval_set=[(X_val, y_val)], # Đánh giá hiệu suất\n",
    "    verbose=True # Hiển thị quá trình\n",
    ")\n",
    "xgb_grid_search.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
